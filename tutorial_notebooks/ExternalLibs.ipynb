{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External libs in RELAY\n",
    "Shows how to use external libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "from tvm.contrib import graph_runtime as runtime\n",
    "from tvm import relay\n",
    "from tvm.relay import testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 16\n",
    "batch_size = 1\n",
    "\n",
    "data = relay.var(\"data\", relay.TensorType((batch_size, 3, 224, 224), \"float32\"))\n",
    "weight = relay.var(\"weight\")\n",
    "bn_gamma = relay.var(\"bn_gamma\")\n",
    "bn_beta = relay.var(\"bn_beta\")\n",
    "bn_mmean = relay.var(\"bn_mean\")\n",
    "bn_mvar = relay.var(\"bn_var\")\n",
    "\n",
    "simple_net = relay.nn.conv2d(\n",
    "    data=data, weight=weight, kernel_size=(3, 3), channels=out_channels, padding=(1, 1)\n",
    ")\n",
    "simple_net = relay.nn.batch_norm(simple_net, bn_gamma, bn_beta, bn_mmean, bn_mvar)[0]\n",
    "simple_net = relay.nn.relu(simple_net)\n",
    "simple_net = relay.Function(relay.analysis.free_vars(simple_net), simple_net)\n",
    "\n",
    "data_shape = (batch_size, 3, 224, 224)\n",
    "net, params = testing.create_workload(simple_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:autotvm:Download pre-tuned parameters package from https://raw.githubusercontent.com/uwsampl/tvm-distro/master/tophub/cuda_v0.09.log\n",
      "...100%, 0.40 MB, 388 KB/s, 1 seconds passed\n",
      "DEBUG:autotvm:Finish loading 688 records\n",
      "INFO:compile_engine:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for sqrt based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for divide based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for multiply based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for expand_dims based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for negative based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cpu for add based on highest priority (10)\n",
      "WARNING:autotvm:Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('conv2d_nchw.cuda', ('TENSOR', (1, 3, 224, 224), 'float32'), ('TENSOR', (16, 3, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "INFO:compile_engine:Using conv2d_nchw.cuda for nn.conv2d based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cuda for multiply based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:compile_engine:Using injective.cuda for nn.relu based on highest priority (10)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x000000011c572a28 TVMFuncCall + 72\n  [bt] (7) 8   libtvm.dylib                        0x000000011c3e3a0e std::__1::__function::__func<tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), std::__1::allocator<tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 62\n  [bt] (6) 7   libtvm.dylib                        0x000000011c3e3ba6 tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const + 342\n  [bt] (5) 6   libtvm.dylib                        0x000000011c3e3d77 tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::Map<tvm::Integer, tvm::Target, void, void> const&, tvm::Target const&) + 135\n  [bt] (4) 5   libtvm.dylib                        0x000000011c3e4212 tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tvm::runtime::NDArray, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, tvm::runtime::NDArray> > > const&) + 978\n  [bt] (3) 4   libtvm.dylib                        0x000000011ba34e0e tvm::build(tvm::Map<tvm::runtime::String, tvm::IRModule, void, void> const&, tvm::Target const&) + 1134\n  [bt] (2) 3   libtvm.dylib                        0x000000011ba33f7e tvm::build(tvm::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&) + 1342\n  [bt] (1) 2   libtvm.dylib                        0x000000011bf01e01 tvm::codegen::Build(tvm::IRModule, tvm::Target) + 1137\n  [bt] (0) 1   libtvm.dylib                        0x000000011b85c5ef dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  File \"/Users/axelstjerngren/uni/Year 4/Project Level 4/tvm/src/target/codegen.cc\", line 58\nTVMError: Check failed: bf != nullptr: target.build.cuda is not enabled",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ad67adc9a855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tvm-0.8.dev0-py3.8-macosx-10.15-x86_64.egg/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(mod, target, target_host, params, mod_name)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtophub_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mbld_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbld_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_runtime_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphRuntimeFactoryModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tvm-0.8.dev0-py3.8-macosx-10.15-x86_64.egg/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mod, target, target_host, params)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Build the IR module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Get artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mgraph_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tvm-0.8.dev0-py3.8-macosx-10.15-x86_64.egg/tvm/_ffi/_ctypes/packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         ):\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x000000011c572a28 TVMFuncCall + 72\n  [bt] (7) 8   libtvm.dylib                        0x000000011c3e3a0e std::__1::__function::__func<tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), std::__1::allocator<tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 62\n  [bt] (6) 7   libtvm.dylib                        0x000000011c3e3ba6 tvm::relay::backend::RelayBuildModule::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::'lambda1'(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const + 342\n  [bt] (5) 6   libtvm.dylib                        0x000000011c3e3d77 tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::Map<tvm::Integer, tvm::Target, void, void> const&, tvm::Target const&) + 135\n  [bt] (4) 5   libtvm.dylib                        0x000000011c3e4212 tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tvm::runtime::NDArray, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, tvm::runtime::NDArray> > > const&) + 978\n  [bt] (3) 4   libtvm.dylib                        0x000000011ba34e0e tvm::build(tvm::Map<tvm::runtime::String, tvm::IRModule, void, void> const&, tvm::Target const&) + 1134\n  [bt] (2) 3   libtvm.dylib                        0x000000011ba33f7e tvm::build(tvm::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&) + 1342\n  [bt] (1) 2   libtvm.dylib                        0x000000011bf01e01 tvm::codegen::Build(tvm::IRModule, tvm::Target) + 1137\n  [bt] (0) 1   libtvm.dylib                        0x000000011b85c5ef dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  File \"/Users/axelstjerngren/uni/Year 4/Project Level 4/tvm/src/target/codegen.cc\", line 58\nTVMError: Check failed: bf != nullptr: target.build.cuda is not enabled"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)  # to dump TVM IR after fusion\n",
    "\n",
    "target = \"cuda\"\n",
    "lib = relay.build_module.build(net, target, params=params)\n",
    "\n",
    "ctx = tvm.context(target, 0)\n",
    "data = np.random.uniform(-1, 1, size=data_shape).astype(\"float32\")\n",
    "module = runtime.GraphModule(lib[\"default\"](ctx))\n",
    "module.set_input(\"data\", data)\n",
    "module.run()\n",
    "out_shape = (batch_size, out_channels, 224, 224)\n",
    "out = module.get_output(0, tvm.nd.empty(out_shape))\n",
    "out_cuda = out.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}